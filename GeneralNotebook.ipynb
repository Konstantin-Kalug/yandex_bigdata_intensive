{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "086b3b6e",
   "metadata": {},
   "source": [
    "# Общий ноутбук с полным решением продуктового анализа велопроката"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac882ca",
   "metadata": {},
   "source": [
    "## Команда"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3cb6f5",
   "metadata": {},
   "source": [
    "Название:\n",
    "\n",
    "**Бигдатка**\n",
    "\n",
    "Участники:\n",
    "* **Калугин Константин** - Тимлид, ответственный за станции\n",
    "* **Зейгман Константин** - Ответственный за байки\n",
    "* **Муляр Никита** - Ответственный за целевую аудиторию\n",
    "\n",
    "Ментор:\n",
    "\n",
    "**Ермаков Егор**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b88e89f",
   "metadata": {},
   "source": [
    "## Предисловие"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8212ef79",
   "metadata": {},
   "source": [
    "Необходимо разбить решение на следующие части:\n",
    "1. Обработка сырого датасета, приведение всех данных к единому стандарту для более удобной работы и автоматизации вычислений\n",
    "2. Разведочный анализ данных, чтобы понять, с какими данными можно поработать\n",
    "3. Анализ станций\n",
    "4. Определение портрета целевой аудитории\n",
    "5. Анализ типов велосипедов\n",
    "6. Проанализировать экономику велопроката\n",
    "7. Сделать выводы\n",
    "\n",
    "Анализ датасета будет состоять из двух частей: выдвижение гипотезы и ее подтверждение (или опровержение, что тоже хорошо)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc2899",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac1761d",
   "metadata": {},
   "source": [
    "### Обработка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df5f693",
   "metadata": {},
   "source": [
    "#### Проблема"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e90e6f",
   "metadata": {},
   "source": [
    "1. Таблицы за 2013-2019 года отличаются по присутствующим данным от таблиц за 2020-2022 год\n",
    "2. В некоторых таблицах данные представлены с кавычками\n",
    "3. В таблицах за 2013-2019 года некоторая информация о станциях находится в других файлах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e616d833",
   "metadata": {},
   "source": [
    "#### Решение проблемы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ff00a",
   "metadata": {},
   "source": [
    "Определяем библиотеки, которые будут задействованы для обработки датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcc5c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import os\n",
    "import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743716cb",
   "metadata": {},
   "source": [
    "Определяем функции, которые будут задествованы для стандартизации записи данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d015cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_first_2013_2019(line):\n",
    "    try:\n",
    "        first_elem = int(line[0])\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def filter_first_2020_2023(line):\n",
    "    if line[0] == 'ride_id':\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def del_quotation_marks(elems):\n",
    "    for i in range(len(elems)):\n",
    "        if '\"' in elems[i]:\n",
    "            elems[i] = elems[i][1:-1]\n",
    "    return elems\n",
    "\n",
    "\n",
    "def map_2013_2019(elems):\n",
    "    try:\n",
    "        if '/' not in elems[1]:\n",
    "            if len(elems[1].split()[1]) != 8:\n",
    "                return ','.join([elems[0], '', datetime.datetime.strptime(elems[1], \"%Y-%m-%d %H:%M\").isoformat(),\n",
    "                                 datetime.datetime.strptime(elems[2], \"%Y-%m-%d %H:%M\").isoformat(), elems[-6],\n",
    "                                 elems[-4], '', '', '', '', elems[-3], elems[-2],\n",
    "                                 str(datetime.datetime.strptime(elems[1], \"%Y-%m-%d %H:%M\").year - int(elems[-1])) if elems[-1] else '', elems[3]])\n",
    "            else:\n",
    "                return ','.join([elems[0], '', datetime.datetime.strptime(elems[1], \"%Y-%m-%d %H:%M:%S\").isoformat(),\n",
    "                                 datetime.datetime.strptime(elems[2], \"%Y-%m-%d %H:%M:%S\").isoformat(), elems[-6],\n",
    "                                 elems[-4], '', '', '', '', elems[-3], elems[-2],\n",
    "                                 str(datetime.datetime.strptime(elems[1], \"%Y-%m-%d %H:%M:%S\").year - int(elems[-1])) if elems[-1] else '', elems[3]])\n",
    "        else:\n",
    "            if elems[1][-3] == ':' and elems[1][-6] == ':':\n",
    "                return ','.join([elems[0], '', datetime.datetime.strptime(elems[1], \"%m/%d/%Y %H:%M:%S\").isoformat(),\n",
    "                                 datetime.datetime.strptime(elems[2], \"%m/%d/%Y %H:%M:%S\").isoformat(), elems[-6],\n",
    "                                 elems[-4], '', '', '', '', elems[-3], elems[-2],\n",
    "                                 str(datetime.datetime.strptime(elems[1], \"%m/%d/%Y %H:%M:%S\").year - int(elems[-1])) if elems[-1] else '', elems[3]])\n",
    "            else:\n",
    "                return ','.join([elems[0], '', datetime.datetime.strptime(elems[1], \"%m/%d/%Y %H:%M\").isoformat(),\n",
    "                             datetime.datetime.strptime(elems[2], \"%m/%d/%Y %H:%M\").isoformat(), elems[-6],\n",
    "                             elems[-4], '', '', '', '', elems[-3], elems[-2],\n",
    "                             str(datetime.datetime.strptime(elems[1], \"%m/%d/%Y %H:%M\").year - int(elems[-1])) if elems[-1] else '', elems[3]])\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def map_2020_2023(elems):\n",
    "     try:\n",
    "        return ','.join([elems[0], elems[1], datetime.datetime.strptime(elems[2], \"%Y-%m-%d %H:%M:%S\").isoformat(),\n",
    "                         datetime.datetime.strptime(elems[3], \"%Y-%m-%d %H:%M:%S\").isoformat(),\n",
    "                         elems[4], elems[6], elems[8], elems[9],\n",
    "                         elems[10], elems[11], elems[12], '', '', ''])\n",
    "     except:\n",
    "         return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c75627",
   "metadata": {},
   "source": [
    "Определяем функции, которые будут задействованы для получения координат станций (требуется для 2013-2019 годов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_st(line):\n",
    "    info = line.split(\",\")\n",
    "    if info[0].isnumeric() and info[1] != \"\" and info[2] != \"\" and info[3] != \"\":\n",
    "        yield (info[0], (info[1], info[2], info[3]))\n",
    "\n",
    "def mapper_tr(line):\n",
    "    id_, type_, started_at, ended_at, start_name, end_name, start_lat, start_lng, end_lat, end_lng, member_casul, gender, age, bikeid = line.split(\",\")\n",
    "    return {\n",
    "        \"id\": int(id_),\n",
    "        \"type\": type_,\n",
    "        \"started_at\": started_at,\n",
    "        \"ended_at\": ended_at,\n",
    "        \"start_name\": start_name,\n",
    "        \"end_name\": end_name,\n",
    "        \"member_casul\": member_casul,\n",
    "        \"gender\": gender,\n",
    "        \"age\": age,\n",
    "        \"bikeid\": bikeid\n",
    "    }\n",
    "\n",
    "def mapper_inter(line):\n",
    "    from_name, (data, station) = line\n",
    "    return {\n",
    "        \"id\": data[\"id\"],\n",
    "        \"type\": data[\"type\"],\n",
    "        \"started_at\": data[\"started_at\"],\n",
    "        \"ended_at\": data[\"ended_at\"],\n",
    "        \"start_name\": data[\"start_name\"],\n",
    "        \"end_name\": data[\"end_name\"],\n",
    "        \"start_lat\": station[\"latitude\"] if station else \"\",\n",
    "        \"start_lng\": station[\"longitude\"] if station else \"\",\n",
    "        \"member_casul\": data[\"member_casul\"],\n",
    "        \"gender\": data[\"gender\"],\n",
    "        \"age\": data[\"age\"],\n",
    "        \"bikeid\": data[\"bikeid\"]\n",
    "    }\n",
    "\n",
    "def mapper_st_final(x):\n",
    "    return {\n",
    "        \"name\": x[1][0],\n",
    "        \"latitude\": x[1][1],\n",
    "        \"longitude\": x[1][2]\n",
    "    }\n",
    "\n",
    "def finalise(line):\n",
    "    to_name, (data, station) = line\n",
    "    return \",\".join([str(x) for x in [\n",
    "        data[\"id\"],\n",
    "        data[\"type\"],\n",
    "        data[\"started_at\"],\n",
    "        data[\"ended_at\"],\n",
    "        data[\"start_name\"],\n",
    "        data[\"end_name\"],\n",
    "        data[\"start_lat\"],\n",
    "        data[\"start_lng\"],\n",
    "        station[\"latitude\"] if station else \"\",\n",
    "        station[\"longitude\"] if station else \"\",\n",
    "        data[\"member_casul\"],\n",
    "        data[\"gender\"],\n",
    "        data[\"age\"],\n",
    "        data[\"bikeid\"]\n",
    "    ]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1381738",
   "metadata": {},
   "source": [
    "Определяем функцию, которая реализует описанные выше функции для стандартизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    directory ='sources/'\n",
    "    # 2013 - 2019\n",
    "    for i in range(2013, 2020):\n",
    "        files = None\n",
    "        try:\n",
    "            for filename in os.listdir(directory):\n",
    "                if str(i) not in filename:\n",
    "                    continue\n",
    "                file = sc.textFile(os.path.join(directory, filename)) \\\n",
    "                    .map(lambda line: line.split(',')) \\\n",
    "                    .map(del_quotation_marks) \\\n",
    "                    .filter(filter_first_2013_2019)\n",
    "                if files is None:\n",
    "                    files = file\n",
    "                else:\n",
    "                    files = files.union(file)\n",
    "            res = files.map(map_2013_2019).filter(lambda x: x != '')\n",
    "            res.coalesce(1).saveAsTextFile(f'clean_sources/{i}')\n",
    "        except:\n",
    "            pass\n",
    "    # 2020 - 2023\n",
    "    for i in range(2020, 2024):\n",
    "        files = None\n",
    "        try:\n",
    "            for filename in os.listdir(directory):\n",
    "                if str(i) not in filename:\n",
    "                    continue\n",
    "                file = sc.textFile(os.path.join(directory, filename)) \\\n",
    "                    .map(lambda line: line.split(',')) \\\n",
    "                    .map(del_quotation_marks) \\\n",
    "                    .filter(filter_first_2020_2023)\n",
    "                if files is None:\n",
    "                    files = file\n",
    "                else:\n",
    "                    files = files.union(file)\n",
    "            res = files.map(map_2020_2023).filter(lambda x: x != '')\n",
    "            res.coalesce(1).saveAsTextFile(f'clean_sources/{i}')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191cd4d",
   "metadata": {},
   "source": [
    "Определяем цункцию, которая будет использоваться для получения координат и добавления ее к датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6703ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bind_data():\n",
    "    # собрать данные о станциях\n",
    "    stations = sc.textFile(\"stations\").flatMap(mapper_st) \\\n",
    "                                      .reduceByKey(lambda a, b: a) \\\n",
    "                                      .map(mapper_st_final)\n",
    "    stations_key = stations.keyBy(lambda x: x[\"name\"])\n",
    "    for y in range(2013, 2019 + 1):\n",
    "        try:\n",
    "            df = sc.textFile(f\"clean_sources/{y}\").map(mapper_tr)\n",
    "            df_from = df.keyBy(lambda x: x[\"start_name\"])\n",
    "            inter = df_from.leftOuterJoin(stations_key) \\\n",
    "                .map(mapper_inter)\n",
    "            df_to = inter.keyBy(lambda x: x[\"end_name\"])\n",
    "            final = df_to.leftOuterJoin(stations_key) \\\n",
    "                .map(finalise) \\\n",
    "                .coalesce(1) \\\n",
    "                .saveAsTextFile(f\"binded_data/{y}\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64561236",
   "metadata": {},
   "source": [
    "Собираем все полученные таблицы в одной папке, остальные удаляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6693479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unity():\n",
    "    os.makedirs('data/src')\n",
    "    for i in range(2013, 2020):\n",
    "        os.rename(f'binded_data/{i}', f'data/src/{i}')\n",
    "    for i in range(2020, 2024):\n",
    "        os.rename(f'clean_sources/{i}', f'data/src/{i}')\n",
    "    shutil.rmtree('binded_data')\n",
    "    shutil.rmtree('clean_sources')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ee623",
   "metadata": {},
   "source": [
    "Запускаем обработку данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca848d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName('test').setMaster('local')\n",
    "sc = SparkContext(conf=conf)\n",
    "get_data()\n",
    "bind_data()\n",
    "unity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e491b8",
   "metadata": {},
   "source": [
    "В итоге мы оставляем следующие колонки:\n",
    "1. id - уникальный идентификатор поездки\n",
    "2. biketype - тип велосипеда\n",
    "3. starttime - время начала поездки\n",
    "4. endtime - время окончания поездки\n",
    "5. startstation - название стартовой станции\n",
    "6. endstation- название конечной станции\n",
    "7. startlat, startlng - координаты стартовой станции\n",
    "8. endlat, endlng - координаты конечной станции\n",
    "9. member_casual - тип пользователя\n",
    "10. age - возраст пользователя\n",
    "11. gender - пол пользователя\n",
    "12. bikeid - уникальный идентификатор велосипеда"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c1a3f",
   "metadata": {},
   "source": [
    "### Разведочный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea49df",
   "metadata": {},
   "source": [
    "#### Цели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a635fdb4",
   "metadata": {},
   "source": [
    "1. Определить основные направления исследований\n",
    "2. Определить какая информация может отсутствовать в различные временные интервалы\n",
    "3. Определить, какие временные интервалы подходят под те или иные направления"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c81df",
   "metadata": {},
   "source": [
    "#### Достижение цели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda0cd2",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядят данные за различные годы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd78e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2013, 2024):\n",
    "    df = pd.read_table(f'data/src/{year}/part-00000', index_col=False, header=None, names=['id', 'biketype', 'starttime', 'endtime', 'startstation', 'endstation', 'startlat', 'startlng', 'endlat', 'endlng', 'member_casual', 'gender', 'age', 'bikeid'], sep=',')\n",
    "    print(year)\n",
    "    print(df.head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f83f6b6",
   "metadata": {},
   "source": [
    "Заметим, что помимо очевидных пропусков в данных за различные периоды, можно заметить, что члены и нечлены помечаются по-разному.\n",
    "\n",
    "Проверим это ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2013, 2024):\n",
    "    df = pd.read_table(f'data/src/{year}/part-00000', index_col=False, header=None, names=['id', 'biketype', 'starttime', 'endtime', 'startstation', 'endstation', 'startlat', 'startlng', 'endlat', 'endlng', 'member_casual', 'gender', 'age', 'bikeid'], sep=',')\n",
    "    print(year)\n",
    "    print(df['member_casual'].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15cc19c",
   "metadata": {},
   "source": [
    "Члены могут быть отмечены в логах как \"member\" или как \"Subscriber\", а нечлены - как \"Customer\" или как \"casual\". Также один раз встречается \"Depended\", но он не представляет для нас никакого интереса в конечном счете"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295efc5b",
   "metadata": {},
   "source": [
    "Определим, как менялось с годами количество станций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7615ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_stations = []\n",
    "for year in range(2013, 2024):\n",
    "    df = pd.read_table(f'data/src/{year}/part-00000', index_col=False, header=None, names=['id', 'biketype', 'starttime', 'endtime', 'startstation', 'endstation', 'startlat', 'startlng', 'endlat', 'endlng', 'member_casual', 'gender', 'age', 'bikeid'], sep=',')\n",
    "    counts_stations.append(len(np.unique(np.concatenate((df['startstation'].dropna().unique(), df['endstation'].dropna().unique()), axis=None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(2013, 2024), counts_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32636c40",
   "metadata": {},
   "source": [
    "Как мы видим по графику, количество станций растет. Падение в конце же обусловлено тем, что мы имеем за последний год только 3 месяца, вместо 12, из-за было собрано мало данных\n",
    "\n",
    "Однако именно на информации за 2023 мы будем основываться в анализе станций, т.к. только с ними мы можем иметь высокую уверенность в том, что станции не были закрыты (к тому же по выборка достаточно большая, что делает ее репрезентативной)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196f431",
   "metadata": {},
   "source": [
    "Посмотрим на то, как могут строиться маршруты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf626eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(f'data/src/2023/part-00000', index_col=False, header=None, names=['id', 'biketype', 'starttime', 'endtime', 'startstation', 'endstation', 'startlat', 'startlng', 'endlat', 'endlng', 'member_casual', 'gender', 'age', 'bikeid'], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb1d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = df[['startstation', 'endstation']]\n",
    "stations.rename(columns={'startstation': 'source', 'endstation': 'target'})\n",
    "graph = nx.Graph()\n",
    "graph.add_edges_from(stations.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ca27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "options = {\"node_color\": \"black\", \"node_size\": 25, \"linewidths\": 0, \"width\": 0.1}\n",
    "pos = nx.spring_layout(graph, seed=1969)\n",
    "nx.draw(graph, pos, **options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55428a9",
   "metadata": {},
   "source": [
    "Как мы видим, в логгах встречаются прогулочные сессии (т.е. человек начал ее и закончил в одном пункте), а также на гарфе мы видим висячие вершины, что говорит о том, что некоторые станции использовались для связи лишь с одним пунктом."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d3dbf",
   "metadata": {},
   "source": [
    "### Целевая аудитория"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7321eed9",
   "metadata": {},
   "source": [
    "### Велосипеды"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133aa886",
   "metadata": {},
   "source": [
    "Определяем функции, которые необходимы для вычисления "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7115fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_distance(lat1, lon1, lat2, lon2):\n",
    "    return acos(sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(lon2 - lon1)) * 6371\n",
    "\n",
    "\n",
    "def parse_table1(line):\n",
    "    id_, type_, startt, endt, startn, endn, startlt, startln, endlt, endln, member, gender, age, bikeid = line.split(\",\")\n",
    "    return (bikeid, 1)\n",
    "\n",
    "\n",
    "def parse_table2(line):\n",
    "    id_, type_, startt, endt, startn, endn, startlt, startln, endlt, endln, member, gender, age, bikeid = line.split(\",\")\n",
    "    V_AVG = 12/3.6/1000\n",
    "    startt = datetime.datetime.strptime(startt, '%Y-%m-%dT%H:%M:%S')\n",
    "    endt = datetime.datetime.strptime(endt, '%Y-%m-%dT%H:%M:%S')\n",
    "    duration = endt - startt\n",
    "    return (bikeid, V_AVG*duration.total_seconds())\n",
    "\n",
    "\n",
    "def parse_table3(line):\n",
    "    id_, type_, startt, endt, startn, endn, startlt, startln, endlt, endln, member, gender, age, bikeid = line.split(\",\")\n",
    "    return (bikeid, startt[0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0fa3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName('test').setMaster('local')\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPAIR_LIM = 10000\n",
    "REPAIR_PRICE = 60\n",
    "eREPAIR_PRICE = 80\n",
    "BIKE_PRICE = 1500\n",
    "eBIKE_PRICE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_by_year = []\n",
    "for y in range(2013, 2019 + 1):\n",
    "    df = sc.textFile(f\"data/src/{y}\").map(parse_table1) \\\n",
    "                                          .reduceByKey(lambda a, b: a + b) \\\n",
    "                                          .map(lambda x: (None, 1)) \\\n",
    "                                          .reduceByKey(lambda a, b: a + b) \\\n",
    "                                          .collect()\n",
    "    unique_by_year.append((y, df[0][1]))\n",
    "print(\"Уникальные велосипеды по годам:\", unique_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be12004",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_repairs = []\n",
    "run = []\n",
    "big = sc.parallelize([])\n",
    "for y in range(2013, 2019 + 1):\n",
    "    df = sc.textFile(f\"data/src/{y}\").map(parse_table2) \\\n",
    "                                          .reduceByKey(lambda a, b: a + b)\n",
    "    big = big.union(df)\n",
    "    analyse_rep = big.map(lambda x: (None, floor(x[1] / REPAIR_LIM))) \\\n",
    "                 .reduceByKey(lambda a, b: a + b) \\\n",
    "                 .collect()\n",
    "    cum_repairs.append((y, analyse_rep[0][1]))\n",
    "    analyse_run = df.map(lambda x: (None, x[1])) \\\n",
    "                    .reduceByKey(lambda a, b: a + b) \\\n",
    "                    .collect()\n",
    "    run.append((y, analyse_run[0][1]))\n",
    "print(\"Накопительное количество ремонтов по годам: \", cum_repairs)\n",
    "print(\"Пробег по годам: \", run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum = 0\n",
    "repairs = []\n",
    "for y, s in cum_repairs:\n",
    "    repairs.append((y, s - cum))\n",
    "    cum = s\n",
    "print(\"Количество ремонтов по годам: \", repairs)\n",
    "repair_prices = [(y, x * 0.6 * eREPAIR_PRICE + x * 0.4 * REPAIR_PRICE) for y, x in repairs]\n",
    "print(\"Затраты на ремонт по годам: \", repair_prices)\n",
    "print(\"Средние затраты по годам: \", sum([x for y, x in repair_prices]) / len(list(filter(lambda x: x[1] != 0, repair_prices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364db3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "big = sc.parallelize([])\n",
    "for y in range(2013, 2019 + 1):\n",
    "    df = sc.textFile(f\"data/src/{y}\").map(parse_table3)\n",
    "    big = big.union(df)\n",
    "\n",
    "unique = big.reduceByKey(lambda a, b: a if a < b else b) \\\n",
    "            .map(lambda x: (x[1], 1)) \\\n",
    "            .reduceByKey(lambda a, b: a + b) \\\n",
    "            .collect()\n",
    "unique_by_year2 = []\n",
    "for y in range(2013, 2019 + 1):\n",
    "    summa = 0\n",
    "    for d, x in unique:\n",
    "        if str(y) in d:\n",
    "            summa += x\n",
    "    unique_by_year2.append((y, summa))\n",
    "print(\"Новые уникальные велосипеды по месяцам:\", unique)\n",
    "print(\"Новые уникальные велосипеды по годам:\", unique_by_year2)\n",
    "avg_bike = sum([x for y, x in unique_by_year2]) / len(unique_by_year2)\n",
    "print(\"Среднее новых по годам: \", avg_bike)\n",
    "print(\"Средние затраты на велосипеды: \", avg_bike * 0.6 * eBIKE_PRICE + avg_bike * 0.4 * BIKE_PRICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc35ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(unique_by_year)\n",
    "plt.plot(pdf[0], pdf[1], c=\"green\")\n",
    "plt.title(\"Количество уникальных байков по годам\")\n",
    "plt.ylabel(\"Количество\")\n",
    "plt.xlabel(\"Год\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff003904",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(repairs)\n",
    "plt.plot(pdf[0], pdf[1], c=\"blue\")\n",
    "plt.title(\"Количество ремонтов байков по годам\")\n",
    "plt.ylabel(\"Количество\")\n",
    "plt.xlabel(\"Год\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c9711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(unique_by_year2)\n",
    "plt.plot(pdf[0], pdf[1], c=\"red\")\n",
    "plt.title(\"Новые уникальные велосипеды по годам\")\n",
    "plt.ylabel(\"Количество\")\n",
    "plt.xlabel(\"Год\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(run)\n",
    "plt.plot(pdf[0], pdf[1], c=\"green\")\n",
    "plt.title(\"Пробег по годам\")\n",
    "plt.ylabel(\"Путь (км)\")\n",
    "plt.xlabel(\"Год\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77717a",
   "metadata": {},
   "source": [
    "Какие выводы можно сделать из графиков за 2013-2019 года?\n",
    "1. Велосипедная сеть росла, лишь в 2019 году наблюдается незначительный спад количества уникальных байков\n",
    "2. В 2016 наблюдается небольшой спад пользования сети (подтверждение о чем можно найти в новостных лентах)\n",
    "3. График ремонта байков будет цикличен. Divvy основан в 2013 году, в этом году введена большая часть велосипедов этой сети (вторая часть была введена в эксплуатацию после расширения сети в 2015 году). Значит, по истечении 2-х лет количество ремонтов байков достигнет пика, затем снова пойдет спад. В 2018 году идет наложение ремонта сразу двух \"подгрупп\" велосипедов (2013 + 2015) => Нужно вводить велосипеды в использование равномерно?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8092870a",
   "metadata": {},
   "source": [
    "### Станции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = df[['id', 'startstation', 'biketype']].rename(columns={'startstation': 'station'}).groupby(by=['station']).agg({'id': 'count', 'biketype': pd.Series.mode}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbba9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.sort_values(by=['id'], ascending=False).rename(columns={\"id\":\"count\"})[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8308f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.sort_values(by=['id'], ascending=False).rename(columns={\"id\":\"count\"})[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94444e6",
   "metadata": {},
   "source": [
    "### Экономика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c2997",
   "metadata": {},
   "source": [
    "## Заключение"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
